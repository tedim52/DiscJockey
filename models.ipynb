{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make a personal DJ in 5 simple steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part1: Setup\n",
    "After importing all of the necessary libraries, we set up the spotipy client credentials using a secrets.env file to save SPOTIPY_CLIENT_ID and SPOTIPY_CLIENT_SECRET. For now we have out in our credentials Having setup the wrapper for the spotify web API, we needed to create a dataframe and populate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spotify API Setup\n",
    "SPOTIPY_CLIENT_ID = \"236e81909708434598e63e00fe671955\"\n",
    "SPOTIPY_CLIENT_SECRET = \"5d574a1eb8f940b783b72b00c5eb4658\"\n",
    "cc = SpotifyClientCredentials(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Data Population and data visualization\n",
    "In order to create a \"DJ\" that would recommend songs to your liking, the DJ first must be trained off of some data.  We decided to train a model off of audio feature data.  All of the audio features are listed below in the array \"columns\" along with other useful information like \"track_id\" and \"song_name\". Then in order to create a populated dataframe we created two helper methods, song_to_df and playlist_to_df, which will return a dataframe of one row with a song and its audio features and return a dataframe of songs respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create music dataframe of party songs and non party songs\n",
    "columns = [\"track_id\", \"song\", \"acousticness\", \"danceability\", \"energy\",\n",
    "            \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\",\n",
    "            \"valence\", \"tempo\", \"party\"]\n",
    "music = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two playlists chosen by us that we subjectively chose as \"party songs\" and \"non-party songs\"\n",
    "#Here's the link to the party playlist we used: https://open.spotify.com/playlist/5ge2YqUbZrmqd2Mve8Uezf?si=m7ms4-EfQj6VFBsN5o-BbA\n",
    "party_playlist_id = \"5ge2YqUbZrmqd2Mve8Uezf?si=VVFB-RkdQMOpy1BffTeozQ\"\n",
    "#Here's the link for the non-party playlist we created to train with: https://open.spotify.com/playlist/5hCRFgctanZE1v1XzTDim4?si=tVGyL48TS-uv_TRHL_FywA\n",
    "non_party_playlist_id = \"5hCRFgctanZE1v1XzTDim4?si=M3NmQZrwTJOElCUKVYCzZg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_to_df(track_id, song_name, party):\n",
    "    song_features = sp.audio_features(track_id)[0]\n",
    "    song_data = {'track_id': track_id,\n",
    "                 'song': song_name,\n",
    "                 'acousticness': song_features.get(\"acousticness\"),\n",
    "                 'danceability': song_features.get(\"danceability\"),\n",
    "                 'energy': song_features.get(\"energy\"),\n",
    "                 'instrumentalness': song_features.get(\"instrumentalness\"),\n",
    "                 'liveness': song_features.get(\"liveness\"),\n",
    "                 'loudness': song_features.get(\"loudness\"),\n",
    "                 'speechiness': song_features.get(\"speechiness\"),\n",
    "                 'valence': song_features.get(\"valence\"),\n",
    "                 'tempo': song_features.get(\"tempo\"),\n",
    "                 'party': party\n",
    "                }\n",
    "    return song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_to_df(df, playlist_id, party):\n",
    "    songs = sp.playlist_tracks(playlist_id).get(\"tracks\").get(\"items\")\n",
    "    music_frame = df\n",
    "    for song in songs:\n",
    "        track = song.get(\"track\")\n",
    "        song_name = track.get(\"name\")\n",
    "        track_id = track.get(\"id\")\n",
    "        song_data = song_to_df(track_id, song_name, party)\n",
    "        music_frame = music_frame.append(song_data, ignore_index=True)\n",
    "\n",
    "        #Get five more songs Spotify says is like this song\n",
    "        recommendations = sp.recommendations(seed_tracks=[track_id], limit = 5).get(\"tracks\")\n",
    "        for recommendation in recommendations:\n",
    "            r_song_name = recommendation.get(\"name\")\n",
    "            r_track_id = recommendation.get(\"id\")\n",
    "            r_song_data = song_to_df(r_track_id, r_song_name, party)\n",
    "            music_frame = music_frame.append(r_song_data, ignore_index=True)\n",
    "    return music_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    track_id  \\\n",
      "0     3FskQrDXcY24ur2fCvz35O   \n",
      "1     3hyKSdJDcYJQgRp3kMrfcs   \n",
      "2     0Sd0kdgU6HrIclxYjuV99j   \n",
      "3     1XFHbzTikXks9CsMq4v8Q3   \n",
      "4     3WyRgi8CzQnhzO0xw79tTS   \n",
      "...                      ...   \n",
      "1315  3PYx9Wte3jwb48V0wArMOy   \n",
      "1316  6MWtB6iiXyIwun0YzU6DFP   \n",
      "1317  3JIqY33zQzdSgmcsMiAhUy   \n",
      "1318  1mC2UjWt25Oixtqu7C6suL   \n",
      "1319  4knL4iPxPOZjQzTUlELGSY   \n",
      "\n",
      "                                                   song  acousticness  \\\n",
      "0                                                    Ye       0.01810   \n",
      "1                                     Floss In The Bank       0.10500   \n",
      "2                                            Break Shit       0.20900   \n",
      "3                               Not So Bad (feat. Emie)       0.00903   \n",
      "4                                             Goin Baby       0.12800   \n",
      "...                                                 ...           ...   \n",
      "1315                                       Keanu Reeves       0.05570   \n",
      "1316                                               Wow.       0.16300   \n",
      "1317                                              I Cry       0.30400   \n",
      "1318  Don't Leave Me Alone (feat. Anne-Marie) - EDX'...       0.04690   \n",
      "1319                     Rake It Up (feat. Nicki Minaj)       0.02200   \n",
      "\n",
      "      danceability  energy instrumentalness  liveness  loudness  speechiness  \\\n",
      "0            0.503   0.592          0.00014    0.1690    -5.923       0.4440   \n",
      "1            0.863   0.770                0    0.0499    -3.832       0.1040   \n",
      "2            0.863   0.587                0    0.0832    -7.455       0.2950   \n",
      "3            0.740   0.674            0.238    0.1540    -4.374       0.0476   \n",
      "4            0.755   0.772                0    0.1570    -5.585       0.4000   \n",
      "...            ...     ...              ...       ...       ...          ...   \n",
      "1315         0.712   0.891                0    0.1340    -6.457       0.2400   \n",
      "1316         0.833   0.539          2.1e-06    0.1010    -7.399       0.1780   \n",
      "1317         0.681   0.727         1.62e-06    0.0655    -5.769       0.1160   \n",
      "1318         0.684   0.818         3.39e-06    0.1190    -4.477       0.1280   \n",
      "1319         0.910   0.444                0    0.1370    -8.126       0.3440   \n",
      "\n",
      "      valence    tempo party  \n",
      "0       0.344  201.850     1  \n",
      "1       0.798  103.932     1  \n",
      "2       0.749   93.290     1  \n",
      "3       0.231  126.017     1  \n",
      "4       0.678  132.906     1  \n",
      "...       ...      ...   ...  \n",
      "1315    0.799  170.130     1  \n",
      "1316    0.385   99.947     1  \n",
      "1317    0.798  121.973     1  \n",
      "1318    0.336  123.938     1  \n",
      "1319    0.530  149.953     1  \n",
      "\n",
      "[1320 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#Visualize audio features of party songs\n",
    "music = playlist_to_df(music, party_playlist_id, 1)\n",
    "music = playlist_to_df(music, non_party_playlist_id, 0)\n",
    "music = music.sample(frac = 1)\n",
    "music = music.reset_index();\n",
    "music = music.drop([\"index\"], axis = 1)\n",
    "print(music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Training models\n",
    "Having visualized the data, we now understood a little more about what kind of audio features make a \"party song\".  So now we wanted to choose a model that would most accuratly predict whether a song is a party or non-party song. So we want the model to predict whether a song is a party song or not, so we decided to mesaure this by having the model output a binary 1 or 0, where 1 means it is a party song and 0 means it is not a party song.  To do this, we passed in a 2 dimensional dataframe with audio feature data as the features, and a dataframe with one column, \"party\", which had a 1 or a 0 based on if we though it was a party song or not. Since we basically want to build a classifier, we looked mainly at classifying models such as K nearest neighbors and Random Tree Classifier. So overall, these models were trained based off of our subjective opinion of what a party song is, to predict whether a given song is considered party or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaughncampos/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/vaughncampos/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting dataframe into train and testing data\n",
    "features = music.drop([\"track_id\", \"song\", \"party\"], axis = 1)\n",
    "target = music[\"party\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)\n",
    "y_train = y_train.astype(\"int\")\n",
    "y_test = y_test.astype(\"int\")\n",
    "\n",
    "#Normalizing values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "#Training MODELS\n",
    "#KNNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN = KNeighborsClassifier(n_neighbors=5)\n",
    "kNN.fit(x_train, y_train)\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "#Random Tree Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "#Support vector machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Analyzing and comparing models\n",
    "We abitrairly chose models to test.  In order to compare the models we wanted to look at a few metrics for each.  First, we wanted to see how accurate the models predictions were to the y_test data.  Then to gain more insight and assert or contradict the accuracy score, we looked at the classification report and confusion matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0.9747474747474747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        11\n",
      "           1       0.98      0.99      0.99       187\n",
      "\n",
      "    accuracy                           0.97       198\n",
      "   macro avg       0.89      0.86      0.87       198\n",
      "weighted avg       0.97      0.97      0.97       198\n",
      "\n",
      "[[  8   3]\n",
      " [  2 185]]\n",
      "Accuracy0.98989898989899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.99      0.99       187\n",
      "\n",
      "    accuracy                           0.99       198\n",
      "   macro avg       0.92      0.99      0.96       198\n",
      "weighted avg       0.99      0.99      0.99       198\n",
      "\n",
      "[[ 11   0]\n",
      " [  2 185]]\n",
      "Accuracy0.9797979797979798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.98      0.99      0.99       187\n",
      "\n",
      "    accuracy                           0.98       198\n",
      "   macro avg       0.94      0.86      0.89       198\n",
      "weighted avg       0.98      0.98      0.98       198\n",
      "\n",
      "[[  8   3]\n",
      " [  1 186]]\n"
     ]
    }
   ],
   "source": [
    "#Metrics for K nearest neighbors\n",
    "y_pred_kNN = kNN.predict(x_test)\n",
    "print(\"Accuracy\" + str(accuracy_score(y_test, y_pred_kNN)))\n",
    "print(classification_report(y_test, y_pred_kNN))\n",
    "print(confusion_matrix(y_test, y_pred_kNN))\n",
    "\n",
    "#Metrics for Logistics regression\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "\n",
    "print(\"Accuracy\" + str(accuracy_score(y_test, y_pred_lr)))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "#Metrics for Random Tree Classifier\n",
    "y_pred_rfc = rfc.predict(x_test)\n",
    "\n",
    "print(\"Accuracy\" + str(accuracy_score(y_test, y_pred_rfc)))\n",
    "print(classification_report(y_test, y_pred_rfc))\n",
    "print(confusion_matrix(y_test, y_pred_rfc))\n",
    "\n",
    "#Metrics for SVM\n",
    "y_pred_svm = svm.predict(x_test)\n",
    "\n",
    "print(\"Accuracy\" + str(accuracy_score(y_test, y_pred_svm)))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5: Choosing a model\n",
    "To choose a model for our DJ, we obviosly wanted the most accurate and most precise model.  When we looked through the accuracy scores, classification reports, and confusion matrices, we came to choose a logistic regression as the model for our DJ.  Although the Random Tree and K nearest neighbors has 97 and 98 percent accuracies, the logistic regression had a 99 percent accuracy.  Also if we look at the precision of classification, the logistic regression predicted 100 percent of party songs correctly.  This means that of the songs returned by the DJ, all party songs will at least be there, with some exceptions of incorrect predictions of non-party songs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
